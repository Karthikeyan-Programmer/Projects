{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e0187a-f4f9-4819-b386-4db34557df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "191a7ff7-5365-4c5d-9d90-e1e49878ed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os  # Operating system-related functions\n",
    "import shutil  # File operations\n",
    "import cv2  # OpenCV for image processing\n",
    "import numpy as np  # NumPy for numerical operatioans\n",
    "import matplotlib.pyplot as plt  # Matplotlib for plotting\n",
    "from skimage import io  # Image I/O from scikit-image\n",
    "import matplotlib.image as mpimg  # Matplotlib for image plotting\n",
    "from sklearn.preprocessing import LabelEncoder  # Encoding categorical labels\n",
    "from keras.preprocessing.sequence import pad_sequences  # Padding sequences for model input\n",
    "import pandas as pd  # Pandas for data manipulation\n",
    "from sklearn.utils import shuffle  # Shuffling data\n",
    "from sklearn.model_selection import train_test_split  # Splitting data into training and testing sets\n",
    "from sklearn.preprocessing import StandardScaler  # Standardizing data\n",
    "from sklearn.metrics import classification_report  # Evaluation metric for classification\n",
    "from tensorflow.keras.models import Sequential, Model  # Keras Sequential model and generic Model\n",
    "from tensorflow.keras.layers import Input, SimpleRNN, Dense, Attention, GlobalAveragePooling1D  # Layers for building neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62039ee5-5ba3-45c8-9b73-02b119968b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dfe7ffe-533b-4a54-a7a1-4d287dd89743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged D:\\dataset\\broadleaf, D:\\dataset\\grass, D:\\dataset\\soil, and D:\\dataset\\soybean into D:\\Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\Data\\1(1).tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\Data\\1(10).tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\Data\\1(100).tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\Data\\1(101).tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\Data\\1(102).tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>D:\\Data\\4(95).tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>D:\\Data\\4(96).tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>D:\\Data\\4(97).tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>D:\\Data\\4(98).tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>D:\\Data\\4(99).tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   image\n",
       "0       D:\\Data\\1(1).tif\n",
       "1      D:\\Data\\1(10).tif\n",
       "2     D:\\Data\\1(100).tif\n",
       "3     D:\\Data\\1(101).tif\n",
       "4     D:\\Data\\1(102).tif\n",
       "...                  ...\n",
       "1995   D:\\Data\\4(95).tif\n",
       "1996   D:\\Data\\4(96).tif\n",
       "1997   D:\\Data\\4(97).tif\n",
       "1998   D:\\Data\\4(98).tif\n",
       "1999   D:\\Data\\4(99).tif\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path \n",
    "import pandas as pd\n",
    "\n",
    "# Source directories\n",
    "broadleaf_folder = r'D:\\dataset\\broadleaf'\n",
    "grass_folder = r'D:\\dataset\\grass'\n",
    "soil_folder = r'D:\\dataset\\soil'\n",
    "soybean_folder = r'D:\\dataset\\soybean'\n",
    "\n",
    "# Output directory\n",
    "output_directory = r'D:\\Data'\n",
    "\n",
    "# Ensure the output directory exists, if not, create it\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Function to merge folders\n",
    "def merge_folders(source_folder, destination_folder):\n",
    "    # Loop through files in the source folder\n",
    "    for file_name in os.listdir(source_folder):\n",
    "        # Get the full path of the source and destination files\n",
    "        source_file = os.path.join(source_folder, file_name)\n",
    "        destination_file = os.path.join(destination_folder, file_name)\n",
    "        # Copy the source file to the destination folder\n",
    "        shutil.copy2(source_file, destination_file)\n",
    "\n",
    "# Merge folders into subdirectories of the output directory\n",
    "merge_folders(broadleaf_folder, os.path.join(output_directory))\n",
    "merge_folders(grass_folder, os.path.join(output_directory))\n",
    "merge_folders(soil_folder, os.path.join(output_directory))\n",
    "merge_folders(soybean_folder, os.path.join(output_directory))\n",
    "\n",
    "# Print a message indicating successful merging\n",
    "print(f'Merged {broadleaf_folder}, {grass_folder}, {soil_folder}, and {soybean_folder} into {output_directory}')\n",
    "\n",
    "datasetPath = Path(r'D:\\Data')\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# List all files in the directory\n",
    "file_list = [f for f in os.listdir(datasetPath) if os.path.isfile(os.path.join(datasetPath, f))]\n",
    "\n",
    "# Create full file paths\n",
    "file_paths = [str(datasetPath / f) for f in file_list]\n",
    "\n",
    "# Assign the file paths to the 'image' column in the DataFrame\n",
    "df['image'] = file_paths\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbe20a8c-ec45-451c-9ab2-ca6ac721376e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contour Detection Algorithm\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_and_save_ROIs(input_folder, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Loop through all images in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(('.tif', '.jpeg', '.png')):\n",
    "            # Read the image\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            img = cv2.imread(image_path)\n",
    "\n",
    "            # Convert the image to grayscale\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Apply contour detection\n",
    "            contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Loop through detected contours\n",
    "            for i, contour in enumerate(contours):\n",
    "                # Extract ROI\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                roi = img[y:y+h, x:x+w]\n",
    "\n",
    "                # Save ROI to output folder\n",
    "                output_path = os.path.join(output_folder, f\"{filename.split('.')[0]}_ROI_{i}.png\")\n",
    "                cv2.imwrite(output_path, roi)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = r\"D:\\Data\"\n",
    "    output_folder = r\"D:\\ROI\"\n",
    "    extract_and_save_ROIs(input_folder, output_folder)\n",
    "\n",
    "    # Path to the output folder\n",
    "    output_files = os.listdir(output_folder)\n",
    "    if output_files:\n",
    "        sample_output_image = os.path.join(output_folder, output_files[0])\n",
    "        # Display the sample output image using matplotlib\n",
    "        print('Contour Detection Algorithm')\n",
    "        plt.title('Extraction of regions of interest Image')\n",
    "        image = plt.imread(sample_output_image)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')  # Turn off axis\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f8cf79-b287-4e07-9842-ed19e4fa3bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after PCA: [[ 1.47831623e+03  2.02603548e+03 -1.94933659e+03 ... -2.67641997e+02\n",
      "  -1.72524601e+02 -1.37860184e+02]\n",
      " [ 2.28317236e+02  1.91607352e+02 -1.50488492e+03 ...  1.74654466e+02\n",
      "   2.72520460e+02  4.43454717e+02]\n",
      " [-6.91698033e+03  1.20293405e+03  6.67363839e+02 ...  1.57895589e+01\n",
      "   2.83595029e+02  1.81609915e+02]\n",
      " ...\n",
      " [-2.48243803e+02  1.62470185e+02 -1.26445367e+03 ...  1.02996034e+02\n",
      "  -2.92736819e+02  2.09393004e+02]\n",
      " [ 2.01433484e+03 -1.10617525e+02  2.83594510e+01 ... -1.72583975e+02\n",
      "   5.64224957e+02 -1.82160909e+00]\n",
      " [-1.23046535e+03  3.44598745e+02 -9.52964125e+02 ... -1.12231890e+02\n",
      "   1.44219444e+01  1.41026150e+02]]\n",
      "Labels: [0 1 2 ... 1 2 3]\n",
      "Processed images saved in: D:\\Processed_ROI\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the directory containing the images\n",
    "input_directory = r'D:\\ROI'\n",
    "\n",
    "# Define the directory to save the processed images\n",
    "output_directory = r'D:\\Processed_ROI'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Define the list to store image features and corresponding labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each file in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".png\"):\n",
    "        # Read the image\n",
    "        img_path = os.path.join(input_directory, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read the image in grayscale\n",
    "        \n",
    "        # Resize the image (optional, depends on your requirements)\n",
    "        img = cv2.resize(img, (128, 128))  # Adjust the size as needed\n",
    "        \n",
    "        # Flatten the image into a 1D array\n",
    "        flattened_img = img.flatten()\n",
    "        \n",
    "        # Append the flattened image to the features list\n",
    "        features.append(flattened_img)\n",
    "        \n",
    "        # Use the entire filename as the label\n",
    "        labels.append(filename)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "X = np.array(features)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "num_components = 50  # Adjust the number of components as needed\n",
    "pca = PCA(n_components=num_components)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Encode labels into numeric values (0, 1, 2, 3)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels) % 4\n",
    "\n",
    "# Print the features and labels after PCA\n",
    "print(\"Features after PCA:\", X_pca)\n",
    "print(\"Labels:\", y)\n",
    "\n",
    "# Loop through each processed image and save it to the output directory\n",
    "for i, pca_img in enumerate(X_pca):\n",
    "    filename = labels[i]\n",
    "    output_path = os.path.join(output_directory, filename)\n",
    "    np.save(output_path, pca_img)\n",
    "\n",
    "print(\"Processed images saved in:\", output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0504ac36-16a9-49c1-b1e2-51ea3a7f9a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (37760, 50)\n",
      "y (37760,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Assuming you have processed_data and labels available\n",
    "X_train_data = X_pca\n",
    "y_train_data = y\n",
    "\n",
    "# Data Augmentation: Duplicate the data to increase the size\n",
    "num_duplicates = 20\n",
    "augmented_X = np.vstack([X_train_data] * num_duplicates)\n",
    "augmented_y = np.concatenate([y_train_data] * num_duplicates)\n",
    "\n",
    "# Data Augmentation: Adding Noise to Numerical Columns\n",
    "noise_stddev = 0.3\n",
    "\n",
    "# Convert NumPy array to a Pandas DataFrame\n",
    "X_train_df = pd.DataFrame(X_train_data)\n",
    "\n",
    "# Add noise to numerical columns\n",
    "numerical_columns = X_train_df.select_dtypes(include=['number']).columns\n",
    "for col in numerical_columns:\n",
    "    X_train_df[col] += np.random.normal(0, noise_stddev, len(X_train_df))\n",
    "\n",
    "# Convert back to NumPy array after adding noise\n",
    "X_train_data = X_train_df.to_numpy()\n",
    "\n",
    "# Data Augmentation: Shuffling Data\n",
    "# Shuffle the data together to maintain correspondence between X and y\n",
    "shuffled_indices = np.arange(len(augmented_X))\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "augmented_X = augmented_X[shuffled_indices]\n",
    "augmented_y = augmented_y[shuffled_indices]\n",
    "\n",
    "# Data Augmentation: Subsampling Data\n",
    "fraction_to_keep = 0.5\n",
    "num_samples_to_keep = int(len(augmented_X) * fraction_to_keep)\n",
    "augmented_X = augmented_X[:num_samples_to_keep]\n",
    "augmented_y = augmented_y[:num_samples_to_keep]\n",
    "print(\"X\",augmented_X.shape)\n",
    "print(\"y\",augmented_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ed842b-7878-4409-911d-eae1082a8654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m850/850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3528 - loss: 1.5164 - val_accuracy: 0.6376 - val_loss: 0.9293\n",
      "Epoch 2/15\n",
      "\u001b[1m850/850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7089 - loss: 0.7770 - val_accuracy: 0.8311 - val_loss: 0.5069\n",
      "Epoch 3/15\n",
      "\u001b[1m850/850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.3933 - val_accuracy: 0.9026 - val_loss: 0.2887\n",
      "Epoch 4/15\n",
      "\u001b[1m850/850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9370 - loss: 0.2136 - val_accuracy: 0.9557 - val_loss: 0.1646\n",
      "Epoch 5/15\n",
      "\u001b[1m850/850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9580 - loss: 0.1399 - val_accuracy: 0.9557 - val_loss: 0.1525\n",
      "Epoch 6/15\n",
      "\u001b[1m850/850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9583 - loss: 0.1250 - val_accuracy: 0.9629 - val_loss: 0.1179\n",
      "Epoch 7/15\n",
      "\u001b[1m850/850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9655 - loss: 0.1039 - val_accuracy: 0.9670 - val_loss: 0.1021\n",
      "Epoch 8/15\n",
      "\u001b[1m850/850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9549 - loss: 0.1257 - val_accuracy: 0.9706 - val_loss: 0.1008\n",
      "Epoch 9/15\n",
      "\u001b[1m850/850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.0835 - val_accuracy: 0.9688 - val_loss: 0.0888\n",
      "Epoch 10/15\n",
      "\u001b[1m850/850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.0803 - val_accuracy: 0.9672 - val_loss: 0.1010\n",
      "Epoch 11/15\n",
      "\u001b[1m850/850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9545 - loss: 0.1234 - val_accuracy: 0.9740 - val_loss: 0.0829\n",
      "Epoch 12/15\n",
      "\u001b[1m850/850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9708 - loss: 0.0739 - val_accuracy: 0.9743 - val_loss: 0.0711\n",
      "Epoch 13/15\n",
      "\u001b[1m850/850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.0705 - val_accuracy: 0.9718 - val_loss: 0.0793\n",
      "Epoch 14/15\n",
      "\u001b[1m850/850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9609 - loss: 0.1062 - val_accuracy: 0.9697 - val_loss: 0.0837\n",
      "Epoch 15/15\n",
      "\u001b[1m850/850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.0712 - val_accuracy: 0.9759 - val_loss: 0.0590\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       934\n",
      "           1       0.97      0.98      0.97       961\n",
      "           2       0.95      0.99      0.97       935\n",
      "           3       0.99      0.97      0.98       946\n",
      "\n",
      "    accuracy                           0.98      3776\n",
      "   macro avg       0.98      0.98      0.98      3776\n",
      "weighted avg       0.98      0.98      0.98      3776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming X_pca and y are already defined\n",
    "# Assuming num_components is defined elsewhere\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(augmented_X, augmented_y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Standardize the features (optional but can be beneficial for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the ANN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(num_components,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='softmax')  # Output layer with 5 neurons for 0 to 4 labels\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=15, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_probs = model.predict(X_test_scaled)\n",
    "y_pred = tf.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b52477-0ecb-480b-862c-d62adc4e0165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
